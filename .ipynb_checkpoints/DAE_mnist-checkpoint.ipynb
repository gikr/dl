{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoders \n",
    "\n",
    "Because the model is forced to prioritize\n",
    "which aspects of the input should be copied, it often learns useful properties of the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaini/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1, 28, 28) float32\n",
      "(2000, 1, 28, 28) float32\n",
      "(2000, 1, 28, 28) float32\n",
      "(2000, 1, 28, 28) float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras, keras.layers as L\n",
    "with np.load('denoising-challenge-01-data.npz') as fh:\n",
    "    training_images_clean = fh['training_images_clean']\n",
    "    validation_images_noisy = fh['validation_images_noisy']\n",
    "    validation_images_clean = fh['validation_images_clean']\n",
    "    test_images_noisy = fh['test_images_noisy']\n",
    "\n",
    "# TRAINING DATA: CLEAN\n",
    "# 1. INDEX: IMAGE SERIAL NUMBER (20000)\n",
    "# 2. INDEX: COLOR CHANNEL (1)\n",
    "# 3/4. INDEX: PIXEL VALUE (28 x 28)\n",
    "print(training_images_clean.shape, training_images_clean.dtype)\n",
    "\n",
    "# VALIDATION DATA: CLEAN + NOISY\n",
    "print(validation_images_clean.shape, validation_images_clean.dtype)\n",
    "print(validation_images_noisy.shape, validation_images_noisy.dtype)\n",
    "\n",
    "# TEST DATA: NOISY\n",
    "print(test_images_noisy.shape, test_images_noisy.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "img_shape = [1,28,28]\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_autoencoder(img_shape,code_size=32):\n",
    "    \"\"\"PCA's deeper brother. See instructions above\"\"\"\n",
    "    C, H,W = img_shape\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "\n",
    "    encoder.add(L.Flatten())\n",
    "    encoder.add(L.Dense(code_size*8, activation='relu'))\n",
    "    encoder.add(L.Dense(code_size*4, activation='tanh'))\n",
    "    encoder.add(L.Dense(code_size*2, activation='tanh'))\n",
    "    encoder.add(L.Dense(code_size))\n",
    "\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "\n",
    "    decoder.add(L.Dense(code_size*2, activation='tanh'))\n",
    "    decoder.add(L.Dense(code_size*4, activation='tanh'))\n",
    "    decoder.add(L.Dense(code_size*8))\n",
    "    decoder.add(L.Dense(np.prod(img_shape), activation='relu'))\n",
    "    decoder.add(L.Reshape(img_shape))\n",
    "\n",
    "    return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder,decoder = build_deep_autoencoder(img_shape,code_size=32)\n",
    "\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inp,reconstruction)\n",
    "autoencoder.compile('adamax','mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 2000 samples\n",
      "Epoch 1/120\n",
      " 2144/20000 [==>...........................] - ETA: 21s - loss: 0.0543"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x=training_images_clean,y=training_images_clean,epochs=120,\n",
    "                validation_data=[validation_images_noisy, validation_images_clean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 26 000 of data. \n",
    "we should train NN to clean noise from data: \n",
    "\n",
    "there are 20 000 clean training set, 2000 clean validation set, 2000 noisy validation set, \n",
    "\n",
    "2000 noisy test set to clean \n",
    "\n",
    "why we are given so many clean set without noised version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL ON training_images_clean\n",
    "\n",
    "# CHECK YOUR MODEL USING (validation_images_clean, validation_images_noisy)\n",
    "\n",
    "# DENOISE IMAGES (test_images_clean) USING test_images_noisy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remained questions:\n",
    "\n",
    "# 1) how to find sigma which is in the noised images\n",
    "\n",
    "# 2) how to use trained network, that is how to clean test data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def apply_gaussian_noise(X,sigma=0.1):\n",
    "    \"\"\"\n",
    "    adds noise from normal distribution with standard deviation sigma\n",
    "    :param X: image tensor of shape [batch,height,width,3]\n",
    "    \"\"\"\n",
    "    \n",
    "    noise = np.random.normal(loc=0.0, scale=sigma, size=X.shape)\n",
    "        \n",
    "    return X + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoder,decoder = build_deep_autoencoder(img_shape,code_size=512)\n",
    "assert encoder.output_shape[1:]==(512,), \"encoder must output a code of required size\"\n",
    "\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inp,reconstruction)\n",
    "autoencoder.compile('adamax','mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(\"Epoch %i/50, Generating corrupted samples...\"%i)\n",
    "    X_train_noise = apply_gaussian_noise(training_images_clean)\n",
    "    #X_test_noise = apply_gaussian_noise(X_test)\n",
    "    \n",
    "    autoencoder.fit(x=training_images_clean,y=training_images_clean,epochs=1,\n",
    "                    validation_data=[validation_images_noisy, validation_images_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
